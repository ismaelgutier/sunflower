---
title: "Example of using sunflower"
author: "Gutiérrez-Cordero"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)

require(sunflower)
require(tidyverse)
require(knitr)
require(kableExtra)
require(rmarkdown)


```

# 0. Intro

In this vignette, we present a practical example of using the sunflower package to work with datasets that include a column of responses containing multiple answers. We demonstrate how to convert the dataset into a long format to obtain formal similarity metrics. Additionally, we illustrate how to perform error classification based on classical criteria found in the literature (e.g., [Dell et al., 1997](https://doi.org/10.1037/0033-295x.104.4.801); [Gold & Kertesz, 2001](https://doi.org/10.1006/brln.2000.2441); see also, [García-Orza et al., 2020](https://doi.org/10.1016/j.cortex.2020.03.020)).


# 1. Managing multiple responses

Load the data `IGC` allocated in the package, select some columns to keep and visualize it.

```{r, view data}

data("IGC")

colnames(IGC)

IGC = IGC %>% select(task_ID, ID, task_type, task_item_ID, item, final_response, correct)

paged_table(IGC, options = list(rows.print = 50, align = "ccc"))
```

Separate the data using the `separate_responses()` function and them rearrange as long format using the `join_responses()` to work in the following step. 

```{r, long data}

IGC_step1 = IGC %>% separate_responses(col_name = "final_response",
                            separate_with = ", ") %>% 
                        get_attempts(first_production = Attempt_1, drop_blank_spaces = T)

View(IGC_step1)

paged_table(IGC_step1, options = list(rows.print = 50, align = "ccc"))

```

# 2. Formal Analysis

Compute the similarity metrics using the `get_metrics()` function.

```{r, formal metrics}

IGC_step2 = IGC_step1 %>% get_formal_metrics(item_col = "item",
                                             response_col = "Response",
                                             attempt_col = "Attempt",
                                             group_cols = c("ID", "task_item_ID"))

paged_table(IGC_step2, options = list(rows.print = 50, align = "c"))

```

## 2.1. Positional Analysis

Obtain the correct characters, in this case, letters, in their correct position using the `position_scores()` function.


```{r, positions}

IGC_step2.1 = IGC_step2 %>% position_scores(match_col = "itemL_adj_strict_match_pos",
                                          last_ID_col = "targetL")

paged_table(IGC_step2.1, options = list(rows.print = 50, align = "c"))

```


# 3. Classifying responses

## 3.1. Prepare dataset

Rerun the previous steps to prepare a functional dataframe.

```{r, get indexes}

data("IGC"); colnames(IGC)

wordlist <- read_csv("dataframes/0_palabras_todas.txt", 
                     col_names = FALSE, 
                     show_col_types = FALSE, 
                     locale = locale(asciify = TRUE)) %>% as.vector()

m_w2v = word2vec::read.word2vec(file = "dataframes/sbw_vectors.bin", normalize = TRUE)

IGC_step2_clean = IGC %>%
                        separate_responses(
                          col_name = "final_response",
                          separate_with = ", ") %>% 
                        get_attempts(
                          first_production = Attempt_1, drop_blank_spaces = T)  %>%
                        select(task_ID, ID, task_item_ID, task_type, item, Response, RA, Attempt) %>% 
                        get_formal_metrics(item_col = "item",
                          response_col = "Response",
                          attempt_col = "Attempt",
                          group_cols = c("ID", "task_item_ID"))

paged_table(IGC_step2_clean, options = list(rows.print = 50, align = "c"))

# remove some values leaving NAs to check that the functions work correctly

IGC_step2_cleanNA = IGC_step2_clean %>%
  mutate(
    Response = if_else(row_number() == 2, NA_character_, Response),
    item = if_else(row_number() == 3, NA_character_, item)
  )

IGC_step3 <- IGC_step2_cleanNA %>% 
  get_formal_similarity_indexes(target_col = "item", response_col = "Response", 
                            item_type = "task_type", source1 = wordlist) %>%
  get_cosine_similarity_df(target_col = "item", response_col = "Response", model = m_w2v)

paged_table(IGC_step3, options = list(rows.print = 50, align = "c"))

```

Proceed with errors classification

```{r, classification}

IGC_step4 <- IGC_step3 %>% classification(access_col = "accessed", RA_col = "RA")

IGC_step4_print <- IGC_step4 %>% select(task_item_ID, item, Response, RA, Attempt, lexicalization:semantic) # keep only errors

paged_table(IGC_step4_print, options = list(rows.print = 50, align = "c"))

```
