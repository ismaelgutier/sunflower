summarize(acc = mean(correct_pos, na.rm = TRUE),
n = n()) %>%
ggplot(aes(x = as.numeric(position), y = acc, group = targetL,
fill = targetL, color = targetL, lty = targetL)) +
geom_line(size = 0.70, alpha = 0.6) +
geom_point(aes(size = n), shape = 21, color = "black", alpha = 0.6) +
scale_linetype_manual(values = custom_linetypes) +
theme(panel.border = element_rect(colour = "black", fill = NA),
panel.background = element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.line = element_blank()) +
scale_x_continuous(breaks = seq(min(positions$position, na.rm = TRUE),
max(positions$position, na.rm = TRUE),
by = 1)) +  # Add ticks for every 1 unit
ylab("Proportion (%) of correct phonemes") +
xlab("Phoneme position") +
guides(fill = guide_legend(title = "Word Length"),
lty = guide_legend(title = "Word Length"),
color = guide_legend(title = "Word Length"),
size = guide_legend(title = "Datapoints")) +
papaja::theme_apa() +
theme(legend.position = "right",
legend.text = element_text(size = 9),
legend.spacing.y = unit(0.1, "cm"),
legend.spacing = unit(-1, "lines"))  # Reduce the space between legend labels
plot_positions
# Calcular la precisión y contar el número de observaciones por grupo
plot_positions <- positions %>%
group_by(position, targetL) %>%
summarize(acc = mean(correct_pos, na.rm = TRUE),
n = n()) %>%
ggplot(aes(x = as.numeric(position), y = acc, group = targetL,
fill = targetL, color = targetL, lty = targetL)) +
geom_line(size = 0.70, alpha = 0.6) +
geom_point(aes(size = n), shape = 21, color = "black", alpha = 0.6) +
scale_linetype_manual(values = custom_linetypes) +
theme(panel.border = element_rect(colour = "black", fill = NA),
panel.background = element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.line = element_blank()) +
scale_x_continuous(breaks = seq(min(positions$position, na.rm = TRUE),
max(positions$position, na.rm = TRUE),
by = 1)) +  # Add ticks for every 1 unit
ylab("Proportion (%) of correct phonemes") +
xlab("Phoneme position") +
guides(fill = guide_legend(title = "Word Length"),
lty = guide_legend(title = "Word Length"),
color = guide_legend(title = "Word Length"),
size = guide_legend(title = "Datapoints")) +
papaja::theme_apa() +
theme(legend.position = "right",
legend.text = element_text(size = 9),
legend.spacing.y = unit(0.01, "cm"),
legend.spacing = unit(-1, "lines"))  # Reduce the space between legend labels
plot_positions
# Calcular la precisión y contar el número de observaciones por grupo
plot_positions <- positions %>%
group_by(position, targetL) %>%
summarize(acc = mean(correct_pos, na.rm = TRUE),
n = n()) %>%
ggplot(aes(x = as.numeric(position), y = acc, group = targetL,
fill = targetL, color = targetL, lty = targetL)) +
geom_line(size = 0.70, alpha = 0.6) +
geom_point(aes(size = n), shape = 21, color = "black", alpha = 0.6) +
scale_linetype_manual(values = custom_linetypes) +
theme(panel.border = element_rect(colour = "black", fill = NA),
panel.background = element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.line = element_blank()) +
scale_x_continuous(breaks = seq(min(positions$position, na.rm = TRUE),
max(positions$position, na.rm = TRUE),
by = 1)) +  # Add ticks for every 1 unit
ylab("Proportion (%) of correct phonemes") +
xlab("Phoneme position") +
guides(fill = guide_legend(title = "Word Length"),
lty = guide_legend(title = "Word Length"),
color = guide_legend(title = "Word Length"),
size = guide_legend(title = "Datapoints")) +
papaja::theme_apa() +
theme(legend.position = "right",
legend.text = element_text(size = 9),
legend.spacing.y = unit(0.001, "cm"),
legend.spacing = unit(-1, "lines"))  # Reduce the space between legend labels
plot_positions
# Calcular la precisión y contar el número de observaciones por grupo
plot_positions <- positions %>%
group_by(position, targetL) %>%
summarize(acc = mean(correct_pos, na.rm = TRUE),
n = n()) %>%
ggplot(aes(x = as.numeric(position), y = acc, group = targetL,
fill = targetL, color = targetL, lty = targetL)) +
geom_line(size = 0.70, alpha = 0.6) +
geom_point(aes(size = n), shape = 21, color = "black", alpha = 0.6) +
scale_linetype_manual(values = custom_linetypes) +
theme(panel.border = element_rect(colour = "black", fill = NA),
panel.background = element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.line = element_blank()) +
scale_x_continuous(breaks = seq(min(positions$position, na.rm = TRUE),
max(positions$position, na.rm = TRUE),
by = 1)) +  # Add ticks for every 1 unit
ylab("Proportion (%) of correct phonemes") +
xlab("Phoneme position") +
guides(fill = guide_legend(title = "Word Length", ncol = 2),  # Set the legend to 2 columns
lty = guide_legend(title = "Word Length", ncol = 2),
color = guide_legend(title = "Word Length", ncol = 2),
size = guide_legend(title = "Datapoints", ncol = 2)) +
papaja::theme_apa() +
theme(legend.position = "right",
legend.text = element_text(size = 9),
legend.spacing.y = unit(0.001, "cm"),
legend.spacing = unit(-1, "lines"))  # Reduce the space between legend labels
# Calcular la precisión y contar el número de observaciones por grupo
plot_positions <- positions %>%
group_by(position, targetL) %>%
summarize(acc = mean(correct_pos, na.rm = TRUE),
n = n()) %>%
ggplot(aes(x = as.numeric(position), y = acc, group = targetL,
fill = targetL, color = targetL, lty = targetL)) +
geom_line(size = 0.70, alpha = 0.6) +
geom_point(aes(size = n), shape = 21, color = "black", alpha = 0.6) +
scale_linetype_manual(values = custom_linetypes) +
theme(panel.border = element_rect(colour = "black", fill = NA),
panel.background = element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.line = element_blank()) +
scale_x_continuous(breaks = seq(min(positions$position, na.rm = TRUE),
max(positions$position, na.rm = TRUE),
by = 1)) +  # Add ticks for every 1 unit
ylab("Proportion (%) of correct phonemes") +
xlab("Phoneme position") +
guides(fill = guide_legend(title = "Word Length", ncol = 2),  # Set the legend to 2 columns
lty = guide_legend(title = "Word Length", ncol = 2),
color = guide_legend(title = "Word Length", ncol = 2),
size = guide_legend(title = "Datapoints", ncol = 2)) +
papaja::theme_apa() +
theme(legend.position = "right",
legend.text = element_text(size = 9),
legend.spacing = unit(-1, "lines"))  # Reduce the space between legend labels
plot_positions
# Calcular la precisión y contar el número de observaciones por grupo
plot_positions <- positions %>%
group_by(position, targetL) %>%
summarize(acc = mean(correct_pos, na.rm = TRUE),
n = n()) %>%
ggplot(aes(x = as.numeric(position), y = acc, group = targetL,
fill = targetL, color = targetL, lty = targetL)) +
geom_line(size = 0.70, alpha = 0.6) +
geom_point(aes(size = n), shape = 21, color = "black", alpha = 0.6) +
scale_linetype_manual(values = custom_linetypes) +
theme(panel.border = element_rect(colour = "black", fill = NA),
panel.background = element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.line = element_blank()) +
scale_x_continuous(breaks = seq(min(positions$position, na.rm = TRUE),
max(positions$position, na.rm = TRUE),
by = 1)) +  # Add ticks for every 1 unit
ylab("Proportion (%) of correct phonemes") +
xlab("Phoneme position") +
guides(fill = guide_legend(title = "Word Length", ncol = 2),  # Set the legend to 2 columns
lty = guide_legend(title = "Word Length", ncol = 2),
color = guide_legend(title = "Word Length", ncol = 2),
size = guide_legend(title = "Datapoints", ncol = 2)) +
papaja::theme_apa() +
theme(legend.position = "right")  # Reduce the space between legend labels
# Calcular la precisión y contar el número de observaciones por grupo
plot_positions <- positions %>%
group_by(position, targetL) %>%
summarize(acc = mean(correct_pos, na.rm = TRUE),
n = n()) %>%
ggplot(aes(x = as.numeric(position), y = acc, group = targetL,
fill = targetL, color = targetL, lty = targetL)) +
geom_line(size = 0.70, alpha = 0.6) +
geom_point(aes(size = n), shape = 21, color = "black", alpha = 0.6) +
scale_linetype_manual(values = custom_linetypes) +
theme(panel.border = element_rect(colour = "black", fill = NA),
panel.background = element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.line = element_blank()) +
scale_x_continuous(breaks = seq(min(positions$position, na.rm = TRUE),
max(positions$position, na.rm = TRUE),
by = 1)) +  # Add ticks for every 1 unit
ylab("Proportion (%) of correct phonemes") +
xlab("Phoneme position") +
guides(fill = guide_legend(title = "Word Length", ncol = 2),  # Set the legend to 2 columns
lty = guide_legend(title = "Word Length", ncol = 2),
color = guide_legend(title = "Word Length", ncol = 2),
size = guide_legend(title = "Datapoints", ncol = 2)) +
papaja::theme_apa() +
theme(legend.position = "right")
plot_positions
install()
# Load required libraries
require(tidyverse)
require(readxl)
require(writexl)
require(here)
require(usethis)
# Set working directory
here()
# Data cleaning code
BPAL_freq <- read_excel(here("data-raw/bpal_freq.xlsx"))
RAE_wordlist <- readLines(here("data-raw/0_palabras_todas_no_conjugaciones.txt"))
# Read and filter datasets
IGC_sample <- read_excel("~/mi paquete de R/sunflower/dataframes/ANC_database_raw_NEW.xlsx") %>%
dplyr::filter(test != "Gutiérrez-Cordero") %>%
mutate(task = case_when(                        # Reemplazar valores en la columna 'task'
task == "BETA" ~ "test1",
task == "EPLA" ~ "test2",
TRUE ~ task                                   # Mantener los valores originales para otros casos
)) %>%
dplyr::filter(!grepl("SnodgrassVanderwart", task_ID)) %>%
dplyr::filter(!grepl("Token", task_ID)) %>%
dplyr::filter(!grepl("WAB", task_ID)) %>%
dplyr::filter(modality == "spoken")  %>%
dplyr::filter(!grepl("nonword", task_type)) %>%
dplyr::filter(task_modality %in% c("repetition", "naming")) %>%
select(ID, task = task_ID, item_ID = task_item_ID, item, response = final_response, correct, accessed)
# Data cleaning code
BPAL_freq <- read_excel(here("data-raw/bpal_freq.xlsx"))
RAE_wordlist <- readLines(here("data-raw/0_palabras_todas_no_conjugaciones.txt"))
# Read and filter datasets
IGC_sample <- read_excel("~/mi paquete de R/sunflower/dataframes/ANC_database_raw_NEW.xlsx") %>%
dplyr::filter(test != "Gutiérrez-Cordero") %>%
mutate(task = case_when(                        # Reemplazar valores en la columna 'task'
task == "BETA" ~ "test1",
task == "EPLA" ~ "test2",
TRUE ~ task                                   # Mantener los valores originales para otros casos
)) %>%
dplyr::filter(!grepl("SnodgrassVanderwart", task_ID)) %>%
dplyr::filter(!grepl("Token", task_ID)) %>%
dplyr::filter(!grepl("WAB", task_ID)) %>%
dplyr::filter(modality == "spoken")  %>%
dplyr::filter(!grepl("nonword", task_type)) %>%
dplyr::filter(task_modality %in% c("repetition", "naming")) %>%
select(ID, task = task_ID, item_ID = task_item_ID, item, response = final_response, correct, accessed)
IGC_long_sample <- read_excel("~/mi paquete de R/sunflower/dataframes/dataframeWORK.xlsx") %>%
dplyr::filter(test != "Gutiérrez-Cordero") %>%
mutate(task = case_when(                        # Reemplazar valores en la columna 'task'
task == "BETA" ~ "test1",
task == "EPLA" ~ "test2",
TRUE ~ task                                   # Mantener los valores originales para otros casos
)) %>%
dplyr::filter(!grepl("SnodgrassVanderwart", test)) %>%
dplyr::filter(!grepl("WAB", test)) %>%
dplyr::filter(!grepl("Token", test)) %>%
dplyr::filter(modality == "spoken")  %>%
dplyr::filter(!grepl("nonword", task_type)) %>%
dplyr::filter(task_modality %in% c("repetition", "naming")) %>%
select(ID, task, item_ID, item, response = Response, accessed, RA, attempt = Attempt)
View(IGC_long_sample)
# Load required libraries
require(tidyverse)
require(readxl)
require(writexl)
require(here)
require(usethis)
# Set working directory
here()
# Data cleaning code
BPAL_freq <- read_excel(here("data-raw/bpal_freq.xlsx"))
# Read and filter datasets
IGC_sample <- read_excel("~/mi paquete de R/sunflower/dataframes/ANC_database_raw_NEW.xlsx") %>%
dplyr::filter(test != "Gutiérrez-Cordero") %>%
mutate(task = case_when(                        # Reemplazar valores en la columna 'task'
task == "BETA" ~ "test1",
task == "EPLA" ~ "test2",
TRUE ~ task                                   # Mantener los valores originales para otros casos
)) %>%
dplyr::filter(!grepl("SnodgrassVanderwart", task_ID)) %>%
dplyr::filter(!grepl("Token", task_ID)) %>%
dplyr::filter(!grepl("WAB", task_ID)) %>%
dplyr::filter(modality == "spoken")  %>%
dplyr::filter(!grepl("nonword", task_type)) %>%
dplyr::filter(task_modality %in% c("repetition", "naming")) %>%
select(ID, task = task_ID, item_ID = task_item_ID, item, response = final_response, correct, accessed)
# Read and filter datasets
IGC_sample <- read_excel("~/mi paquete de R/sunflower/dataframes/ANC_database_raw_NEW.xlsx") %>%
dplyr::filter(test != "Gutiérrez-Cordero") %>%
mutate(task_ID = case_when(              # Actualizar la columna 'task_ID'
task == "BETA" ~ "test1",
task == "EPLA" ~ "test2",
TRUE ~ task_ID                         # Mantener los valores originales si no coincide con las condiciones
)) %>%
dplyr::filter(!grepl("SnodgrassVanderwart", task_ID)) %>%
dplyr::filter(!grepl("Token", task_ID)) %>%
dplyr::filter(!grepl("WAB", task_ID)) %>%
dplyr::filter(modality == "spoken")  %>%
dplyr::filter(!grepl("nonword", task_type)) %>%
dplyr::filter(task_modality %in% c("repetition", "naming")) %>%
select(ID, task = task_ID, item_ID = task_item_ID, item, response = final_response, correct, accessed)
# Read and filter datasets
IGC_sample <- read_excel("~/mi paquete de R/sunflower/dataframes/ANC_database_raw_NEW.xlsx") %>%
dplyr::filter(test != "Gutiérrez-Cordero") %>%
mutate(task_ID = str_replace_all(task_ID, c(
"BETA" = "test1",
"EPLA" = "test2"
))) %>%
dplyr::filter(!grepl("SnodgrassVanderwart", task_ID)) %>%
dplyr::filter(!grepl("Token", task_ID)) %>%
dplyr::filter(!grepl("WAB", task_ID)) %>%
dplyr::filter(modality == "spoken")  %>%
dplyr::filter(!grepl("nonword", task_type)) %>%
dplyr::filter(task_modality %in% c("repetition", "naming")) %>%
select(ID, task = task_ID, item_ID = task_item_ID, item, response = final_response, correct, accessed)
# Read and filter datasets
IGC_sample <- read_excel("~/mi paquete de R/sunflower/dataframes/ANC_database_raw_NEW.xlsx") %>%
dplyr::filter(test != "Gutiérrez-Cordero") %>%
mutate(task_ID = str_replace_all(task_ID, c(
"BETA" = "test10",
"EPLA" = "sometest2"
))) %>%
dplyr::filter(!grepl("SnodgrassVanderwart", task_ID)) %>%
dplyr::filter(!grepl("Token", task_ID)) %>%
dplyr::filter(!grepl("WAB", task_ID)) %>%
dplyr::filter(modality == "spoken")  %>%
dplyr::filter(!grepl("nonword", task_type)) %>%
dplyr::filter(task_modality %in% c("repetition", "naming")) %>%
select(ID, task = task_ID, item_ID = task_item_ID, item, response = final_response, correct, accessed)
IGC_long_sample <- read_excel("~/mi paquete de R/sunflower/dataframes/dataframeWORK.xlsx") %>%
dplyr::filter(test != "Gutiérrez-Cordero") %>%
mutate(task_ID = str_replace_all(task_ID, c(
"BETA" = "test10",
"EPLA" = "sometest2"
))) %>%
dplyr::filter(!grepl("SnodgrassVanderwart", test)) %>%
dplyr::filter(!grepl("WAB", test)) %>%
dplyr::filter(!grepl("Token", test)) %>%
dplyr::filter(modality == "spoken")  %>%
dplyr::filter(!grepl("nonword", task_type)) %>%
dplyr::filter(task_modality %in% c("repetition", "naming")) %>%
select(ID, task, item_ID, item, response = Response, accessed, RA, attempt = Attempt)
IGC_long_sample <- read_excel("~/mi paquete de R/sunflower/dataframes/dataframeWORK.xlsx") %>%
dplyr::filter(test != "Gutiérrez-Cordero") %>%
mutate(task = str_replace_all(task, c(
"BETA" = "test10",
"EPLA" = "sometest2"
))) %>%
dplyr::filter(!grepl("SnodgrassVanderwart", test)) %>%
dplyr::filter(!grepl("WAB", test)) %>%
dplyr::filter(!grepl("Token", test)) %>%
dplyr::filter(modality == "spoken")  %>%
dplyr::filter(!grepl("nonword", task_type)) %>%
dplyr::filter(task_modality %in% c("repetition", "naming")) %>%
select(ID, task, item_ID, item, response = Response, accessed, RA, attempt = Attempt)
IGC_long_phon_sample <- read_excel("~/mi paquete de R/sunflower/dataframes/dataframeWORKphono.xlsx") %>%
dplyr::filter(test != "Gutiérrez-Cordero") %>%
mutate(task = str_replace_all(task, c(
"BETA" = "test10",
"EPLA" = "sometest2"
))) %>%
dplyr::filter(!grepl("SnodgrassVanderwart", test)) %>%
dplyr::filter(!grepl("WAB", test)) %>%
dplyr::filter(!grepl("Token", test)) %>%
dplyr::filter(modality == "spoken")  %>%
dplyr::filter(!grepl("nonword", task_type)) %>%
dplyr::filter(task_modality %in% c("repetition", "naming")) %>%
select(ID, task, item_ID, item, response, item_phon, response_phon, accessed, RA, attempt = Attempt)
# Save datasets as xlsx files
write_xlsx(IGC_sample, path = "C:/Users/Maria/Desktop/sunflower 2025/data-raw/IGC_sample.xlsx")
# Save datasets as xlsx files
write_xlsx(IGC_sample, path = "C:/Users/Maria/Desktop/sunflower/data-raw/IGC_sample.xlsx")
write_xlsx(IGC_long_sample, path = "C:/Users/Maria/Desktop/sunflower/data-raw/IGC_long_sample.xlsx")
write_xlsx(IGC_long_phon_sample, path = "C:/Users/Maria/Desktop/sunflower/data-raw/IGC_long_phon_sample.xlsx")
usethis::use_data(IGC_sample, overwrite = TRUE)
usethis::use_data(IGC_long_sample, overwrite = TRUE)
usethis::use_data(IGC_long_phon_sample, overwrite = TRUE)
View(IGC_long_phon_sample)
# Read and filter datasets
IGC_sample <- read_excel("~/mi paquete de R/sunflower/dataframes/ANC_database_raw_NEW.xlsx") %>%
dplyr::filter(test != "Gutiérrez-Cordero") %>%
mutate(task_ID = str_replace_all(task_ID, c(
"BETA" = "test10",
"EPLA" = "sometest2",
"task" = "123"
))) %>%
dplyr::filter(!grepl("SnodgrassVanderwart", task_ID)) %>%
dplyr::filter(!grepl("Token", task_ID)) %>%
dplyr::filter(!grepl("WAB", task_ID)) %>%
dplyr::filter(modality == "spoken")  %>%
dplyr::filter(!grepl("nonword", task_type)) %>%
dplyr::filter(task_modality %in% c("repetition", "naming")) %>%
select(ID, task = task_ID, item_ID = task_item_ID, item, response = final_response, correct, accessed)
IGC_long_sample <- read_excel("~/mi paquete de R/sunflower/dataframes/dataframeWORK.xlsx") %>%
dplyr::filter(test != "Gutiérrez-Cordero") %>%
mutate(task = str_replace_all(task, c(
"BETA" = "test10",
"EPLA" = "sometest2",
"task" = "123"
))) %>%
dplyr::filter(!grepl("SnodgrassVanderwart", test)) %>%
dplyr::filter(!grepl("WAB", test)) %>%
dplyr::filter(!grepl("Token", test)) %>%
dplyr::filter(modality == "spoken")  %>%
dplyr::filter(!grepl("nonword", task_type)) %>%
dplyr::filter(task_modality %in% c("repetition", "naming")) %>%
select(ID, task, item_ID, item, response = Response, accessed, RA, attempt = Attempt)
IGC_long_phon_sample <- read_excel("~/mi paquete de R/sunflower/dataframes/dataframeWORKphono.xlsx") %>%
dplyr::filter(test != "Gutiérrez-Cordero") %>%
mutate(task = str_replace_all(task, c(
"BETA" = "test10",
"EPLA" = "sometest2",
"task" = "123"
))) %>%
dplyr::filter(!grepl("SnodgrassVanderwart", test)) %>%
dplyr::filter(!grepl("WAB", test)) %>%
dplyr::filter(!grepl("Token", test)) %>%
dplyr::filter(modality == "spoken")  %>%
dplyr::filter(!grepl("nonword", task_type)) %>%
dplyr::filter(task_modality %in% c("repetition", "naming")) %>%
select(ID, task, item_ID, item, response, item_phon, response_phon, accessed, RA, attempt = Attempt)
# Save datasets as xlsx files
write_xlsx(IGC_sample, path = "C:/Users/Maria/Desktop/sunflower/data-raw/IGC_sample.xlsx")
write_xlsx(IGC_long_sample, path = "C:/Users/Maria/Desktop/sunflower/data-raw/IGC_long_sample.xlsx")
write_xlsx(IGC_long_phon_sample, path = "C:/Users/Maria/Desktop/sunflower/data-raw/IGC_long_phon_sample.xlsx")
usethis::use_data(IGC_sample, overwrite = TRUE)
usethis::use_data(IGC_long_sample, overwrite = TRUE)
usethis::use_data(IGC_long_phon_sample, overwrite = TRUE)
View(IGC_long_sample)
install()
df_to_formal_metrics = readxl::read_xlsx("manuscript/data/long_with_phon.xlsx") %>%
dplyr::select(ID_general, test, task_type, task_modality, ID,
item_ID = task_item_ID, item, response,
RA = cda_behavior, attempt = Attempt,
item_phon = target_word_transcrito_clean, response_phon = response_word_transcrito_clean) %>%
dplyr::filter(test %in% c("SnodgrassVanderwart", "BETA", "EPLA", "Gutiérrez-Cordero")) %>%
dplyr::filter(!stringr::str_detect(task_type, "nonword")) %>%
dplyr::arrange(ID)
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>",
fig.path = "man/figures/README-",
out.width = "100%"
)
require("sunflower")
require("tidyverse")
require("htmltools")
require("readxl")
df_to_formal_metrics = sunflower::IGC_long_phon_sample
df_to_formal_metrics = readxl::read_xlsx("manuscript/data/long_with_phon.xlsx") %>%
dplyr::select(ID_general, test, task_type, task_modality, ID,
item_ID = task_item_ID, item, response,
RA = cda_behavior, attempt = Attempt,
item_phon = target_word_transcrito_clean, response_phon = response_word_transcrito_clean) %>%
dplyr::filter(test %in% c("SnodgrassVanderwart", "BETA", "EPLA", "Gutiérrez-Cordero")) %>%
dplyr::filter(!stringr::str_detect(task_type, "nonword")) %>%
dplyr::arrange(ID)
formal_metrics_computed = df_to_formal_metrics %>%
get_formal_similarity(item_col = "item",
response_col = "response",
attempt_col = "attempt",
group_cols = c("ID", "item_ID"))
formal_metrics_computed = formal_metrics_computed %>%
mutate(test = str_replace_all(test, c(
"BETA" = "a_given_test",
)))
formal_metrics_computed
formal_metrics_computed = formal_metrics_computed %>%
mutate(test = str_replace_all(test, c(
"BETA" = "a_given_test",
)))
formal_metrics_computed = formal_metrics_computed %>%
mutate(test = str_replace_all(test, c(
"BETA" = "a_given_test",
)))
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>",
fig.path = "man/figures/README-",
out.width = "100%"
)
require("sunflower")
require("tidyverse")
require("htmltools")
require("readxl")
df_to_formal_metrics = sunflower::IGC_long_phon_sample
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>",
fig.path = "man/figures/README-",
out.width = "100%"
)
require("sunflower")
require("tidyverse")
require("htmltools")
require("readxl")
df_to_formal_metrics = sunflower::IGC_long_phon_sample
require("sunflower")
require("tidyverse")
require("htmltools")
require("readxl")
df_to_formal_metrics = sunflower::IGC_long_phon_sample
sunflower
df_to_formal_metrics = sunflower::IGC_long_sample
df_to_formal_metrics = sunflower::IGC_long_phon_sample.Rda
# Load required libraries
require(tidyverse)
require(readxl)
require(writexl)
require(here)
require(usethis)
# Set working directory
here()
# Data cleaning code
BPAL_freq <- read_excel(here("data-raw/bpal_freq.xlsx"))
