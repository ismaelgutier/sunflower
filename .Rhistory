IGC_long_phon <- IGC_long_phon %>%
mutate(Attempt = as.numeric(Attempt)) %>%  # Convertir Attempt a numérico
group_by(task) %>%                     # Agrupar solo por task
arrange(item_ID) %>%                   # Ordenar por item_ID
#slice_head(n = 25) %>%                 # Obtener las primeras 10 filas por task
ungroup() %>%
select(ID, task, item_ID, item, response, item_phon, response_phon, RA, Attempt, accessed)
# Save xlsxs
write_xlsx(IGC, path = "data-raw/IGC.xlsx")
write_xlsx(IGC_long, path = "data-raw/IGC_long.xlsx")
write_xlsx(IGC_long_phon, path = "data-raw/IGC_long_phon.xlsx")
# Read xlsx to ensure clean dfs
IGC <- read_xlsx("data-raw/IGC.xlsx")
IGC_long <- read_xlsx("data-raw/IGC_long.xlsx")
IGC_long_phon <- read_xlsx("data-raw/IGC_long_phon.xlsx")
# Save read xlsxs as Rdas
save(IGC, IGC, IGC, file = "data/mine/IGC.RData")
save(IGC_long, IGC_long, IGC_long, file = "data/mine/IGC_long.RData")
save(IGC_long_phon, IGC_long_phon, IGC_long_phon, file = "data/mine/IGC_long_phon.RData")
document()
install()
print(2)
IGC_long_phon_sample
df_to_formal_metrics = sunflower::IGC_long_phon_sample
formal_metrics_computed = df_to_formal_metrics %>%
get_formal_similarity(item_col = "item_phon",
response_col = "response_phon",
attempt_col = "attempt",
group_cols = c("ID", "item_ID"))
formal_metrics_computed %>% head(8) %>% knitr::kable()
positions_accuracy = formal_metrics_computed %>%
positional_accuracy(item_col = "item_phon", response_col = "response_phon",
match_col = "adj_strict_match_pos")
@export
#' )
#'
#' # Using the positional_accuracy function
#' result_positions <- positional_accuracy(df,
#'                                         match_col = "itemL_adj_strict_match_pos",
#'                                         item_col = "item",
#'                                         response_col = "Response")
#' print(result_positions)
#'
#' @export
positional_accuracy <- function(df, match_col, item_col, response_col) {
# Ensure input columns are correctly referenced
if (!all(c(match_col, item_col, response_col) %in% colnames(df))) {
stop("One or more column names do not exist in the data frame.")
}
# Extract the column of interest
strings <- df[[match_col]]
# Split each string into a list of vectors
split_strings <- stringr::str_split(strings, "", simplify = FALSE)
# Find the maximum number of characters in the strings
max_length <- max(purrr::map_int(split_strings, length))
# Create a data frame with the separated columns
split_df <- purrr::map_dfc(seq_len(max_length), function(i) {
purrr::map_chr(split_strings, function(s) {
if (i <= length(s)) s[i] else NA_character_
})
})
# Rename the columns
colnames(split_df) <- paste0("x", seq_len(max_length))
# Join the original data frame with the separated data frame
df_separated <- df %>%
dplyr::bind_cols(split_df)
# Transform to long format and apply filters
df_long <- df_separated %>%
# Select all columns except those starting with 'x'
dplyr::select(!tidyselect::starts_with("x")) %>%
# Add back the 'x' columns
dplyr::bind_cols(split_df) %>%
# Transform to long format
tidyr::pivot_longer(cols = tidyselect::starts_with("x"), names_to = "position", values_to = "correct_pos", names_repair = "minimal") %>%
# Rename 'position' column by removing the 'x' prefix
dplyr::mutate(position = as.numeric(stringr::str_remove(position, "^x"))) %>%
# Filter rows where x1 has NA (keep those rows)
dplyr::filter(!is.na(correct_pos) | position == 1) %>%
# Remove rows where all columns from x2 onward are NA
dplyr::group_by(across(!c(position, correct_pos))) %>%
dplyr::filter(!all(is.na(correct_pos) & position != 1)) %>%
dplyr::ungroup() %>%
# Create new columns for elements in item and response based on position
dplyr::mutate(
element_in_item = substr(!!rlang::sym(item_col), position, position),
element_in_response = substr(!!rlang::sym(response_col), position, position)
) %>%
# Replace any out-of-bounds positions with NA
dplyr::mutate(
element_in_item = if_else(position <= nchar(!!rlang::sym(item_col)), element_in_item, NA_character_),
element_in_response = if_else(position <= nchar(!!rlang::sym(response_col)), element_in_response, NA_character_)
)
# Return the modified data frame
return(df_long)
}
positions_accuracy = formal_metrics_computed %>%
positional_accuracy(item_col = "item_phon",
response_col = "response_phon",
match_col = "adj_strict_match_pos")
@export
#' )
#'
#' # Using the positional_accuracy function
#' result_positions <- positional_accuracy(df,
#'                                         match_col = "itemL_adj_strict_match_pos",
#'                                         item_col = "item",
#'                                         response_col = "Response")
#' print(result_positions)
#'
#' @export
positional_accuracy <- function(df, match_col, item_col, response_col) {
# Ensure input columns are correctly referenced
if (!all(c(match_col, item_col, response_col) %in% colnames(df))) {
stop("One or more column names do not exist in the data frame.")
}
# Extract the column of interest
strings <- df[[match_col]]
# Split each string into a list of vectors
split_strings <- stringr::str_split(strings, "", simplify = FALSE)
# Find the maximum number of characters in the strings
max_length <- max(purrr::map_int(split_strings, length))
# Create a data frame with the separated columns
split_df <- purrr::map_dfc(seq_len(max_length), function(i) {
purrr::map_chr(split_strings, function(s) {
if (i <= length(s)) s[i] else NA_character_
})
})
# Rename the columns
colnames(split_df) <- paste0("x", seq_len(max_length))
# Join the original data frame with the separated data frame
df_separated <- df %>%
dplyr::bind_cols(split_df)
# Transform to long format and apply filters
df_long <- df_separated %>%
# Select all columns except those starting with 'x'
dplyr::select(!tidyselect::starts_with("x")) %>%
# Add back the 'x' columns
dplyr::bind_cols(split_df) %>%
# Transform to long format
tidyr::pivot_longer(cols = tidyselect::starts_with("x"), names_to = "position", values_to = "correct_pos", names_repair = "minimal") %>%
# Rename 'position' column by removing the 'x' prefix
dplyr::mutate(position = as.numeric(stringr::str_remove(position, "^x"))) %>%
# Filter rows where x1 has NA (keep those rows)
dplyr::filter(!is.na(correct_pos) | position == 1) %>%
# Remove rows where all columns from x2 onward are NA
dplyr::group_by(across(!c(position, correct_pos))) %>%
dplyr::filter(!all(is.na(correct_pos) & position != 1)) %>%
dplyr::ungroup() %>%
# Create new columns for elements in item and response based on position
dplyr::mutate(
element_in_item = substr(!!rlang::sym(item_col), position, position),
element_in_response = substr(!!rlang::sym(response_col), position, position)
) %>%
# Replace any out-of-bounds positions with NA
dplyr::mutate(
element_in_item = dplyr::if_else(position <= nchar(!!rlang::sym(item_col)), element_in_item, NA_character_),
element_in_response = dplyr::if_else(position <= nchar(!!rlang::sym(response_col)), element_in_response, NA_character_)
)
# Return the modified data frame
return(df_long)
}
positions_accuracy = formal_metrics_computed %>%
positional_accuracy(item_col = "item_phon",
response_col = "response_phon",
match_col = "adj_strict_match_pos")
# Convertir targetL a character para evitar problemas al combinar dataframes
positions_accuracy <- positions_accuracy %>%
mutate(targetL = as.character(targetL))
# Convertir targetL a character para evitar problemas al combinar dataframes
positions_accuracy <- positions_accuracy %>%
dplyr::mutate(targetL = as.character(targetL))
# Duplicar y modificar el dataframe para crear 'positions_general'
positions_general <- positions_accuracy %>%
dplyr::mutate(targetL = "General")
# Combinar ambos dataframes
positions <- bind_rows(positions_accuracy, positions_general)
# Combinar ambos dataframes
positions <- dplyr::bind_rows(positions_accuracy, positions_general)
# Especificar manualmente los niveles en el orden deseado
desired_levels <- c("3", "4", "5", "6", "7", "8", "9", "10", "11", "12",
"13", "14", "15", "17", "21", "22", "24", "48", "General")
# Convertir correct_pos a numérico y ordenar targetL como factor según desired_levels
positions <- positions %>%
mutate(correct_pos = as.numeric(correct_pos),
targetL = factor(targetL, levels = desired_levels)) %>%
arrange(correct_pos, targetL)
# Convertir correct_pos a numérico y ordenar targetL como factor según desired_levels
positions <- positions %>%
dplyr::mutate(correct_pos = as.numeric(correct_pos),
targetL = factor(targetL, levels = desired_levels)) %>%
dplyr::arrange(correct_pos, targetL)
# Definir un conjunto de linetypes que se pueda repetir
custom_linetypes <- rep(c("solid", "dashed", "dotted", "longdash", "dotdash"),
length.out = nlevels(positions$targetL))
# Calcular la precisión y contar el número de observaciones por grupo
plot_positions <- positions %>%
group_by(position, targetL) %>%
summarize(acc = mean(correct_pos, na.rm = TRUE),
n = n()) %>%
ggplot(aes(x = as.numeric(position), y = acc, group = targetL,
fill = targetL, color = targetL, lty = targetL)) +
geom_line(size = 0.70, alpha = 0.6) +
geom_point(aes(size = n), shape = 21, color = "black", alpha = 0.6) +
scale_linetype_manual(values = custom_linetypes) +
theme(panel.border = element_rect(colour = "black", fill = NA),
panel.background = element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.line = element_blank()) +
ylab("Proportion (%) of correct phonemes") +
xlab("Phoneme position") +
guides(fill = guide_legend(title = "Word Length"),
lty = guide_legend(title = "Word Length"),
color = guide_legend(title = "Word Length"),
size = guide_legend(title = "Datapoints")) +
theme_gray() +
theme(legend.position = "right",
legend.key.size = unit(0.6, "lines"))
# Calcular la precisión y contar el número de observaciones por grupo
plot_positions <- positions %>%
dplyr::group_by(position, targetL) %>%
dplyr::summarize(acc = mean(correct_pos, na.rm = TRUE),
n = n()) %>%
ggplot2::ggplot(aes(x = as.numeric(position), y = acc, group = targetL,
fill = targetL, color = targetL, lty = targetL)) +
geom_line(size = 0.70, alpha = 0.6) +
geom_point(aes(size = n), shape = 21, color = "black", alpha = 0.6) +
scale_linetype_manual(values = custom_linetypes) +
theme(panel.border = element_rect(colour = "black", fill = NA),
panel.background = element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.line = element_blank()) +
ylab("Proportion (%) of correct phonemes") +
xlab("Phoneme position") +
guides(fill = guide_legend(title = "Word Length"),
lty = guide_legend(title = "Word Length"),
color = guide_legend(title = "Word Length"),
size = guide_legend(title = "Datapoints")) +
theme_gray() +
theme(legend.position = "right",
legend.key.size = unit(0.6, "lines"))
# Calcular la precisión y contar el número de observaciones por grupo
plot_positions <- positions %>%
dplyr::group_by(position, targetL) %>%
dplyr::summarize(acc = dplyr::mean(correct_pos, na.rm = TRUE),
n = dplyr::n()) %>%
ggplot2::ggplot(aes(x = as.numeric(position), y = acc, group = targetL,
fill = targetL, color = targetL, lty = targetL)) +
geom_line(size = 0.70, alpha = 0.6) +
geom_point(aes(size = n), shape = 21, color = "black", alpha = 0.6) +
scale_linetype_manual(values = custom_linetypes) +
theme(panel.border = element_rect(colour = "black", fill = NA),
panel.background = element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.line = element_blank()) +
ylab("Proportion (%) of correct phonemes") +
xlab("Phoneme position") +
guides(fill = guide_legend(title = "Word Length"),
lty = guide_legend(title = "Word Length"),
color = guide_legend(title = "Word Length"),
size = guide_legend(title = "Datapoints")) +
theme_gray() +
theme(legend.position = "right",
legend.key.size = unit(0.6, "lines"))
# Calcular la precisión y contar el número de observaciones por grupo
plot_positions <- positions %>%
dplyr::group_by(position, targetL) %>%
dplyr::summarize(acc = mean(correct_pos, na.rm = TRUE),
n = dplyr::n()) %>%
ggplot2::ggplot(aes(x = as.numeric(position), y = acc, group = targetL,
fill = targetL, color = targetL, lty = targetL)) +
geom_line(size = 0.70, alpha = 0.6) +
geom_point(aes(size = n), shape = 21, color = "black", alpha = 0.6) +
scale_linetype_manual(values = custom_linetypes) +
theme(panel.border = element_rect(colour = "black", fill = NA),
panel.background = element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.line = element_blank()) +
ylab("Proportion (%) of correct phonemes") +
xlab("Phoneme position") +
guides(fill = guide_legend(title = "Word Length"),
lty = guide_legend(title = "Word Length"),
color = guide_legend(title = "Word Length"),
size = guide_legend(title = "Datapoints")) +
theme_gray() +
theme(legend.position = "right",
legend.key.size = unit(0.6, "lines"))
# Calcular la precisión y contar el número de observaciones por grupo
plot_positions <- positions %>%
dplyr::group_by(position, targetL) %>%
dplyr::summarize(acc = mean(correct_pos, na.rm = TRUE),
n = dplyr::n()) %>%
ggplot2::ggplot(aes(x = as.numeric(position), y = acc, group = targetL,
fill = targetL, color = targetL, lty = targetL)) +
ggplot2::geom_line(size = 0.70, alpha = 0.6) +
ggplot2::geom_point(ggplot2::aes(size = n), shape = 21, color = "black", alpha = 0.6) +
ggplot2::scale_linetype_manual(values = custom_linetypes) +
theme(panel.border = element_rect(colour = "black", fill = NA),
panel.background = element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.line = element_blank()) +
ylab("Proportion (%) of correct phonemes") +
xlab("Phoneme position") +
guides(fill = guide_legend(title = "Word Length"),
lty = guide_legend(title = "Word Length"),
color = guide_legend(title = "Word Length"),
size = guide_legend(title = "Datapoints")) +
theme_gray() +
theme(legend.position = "right",
legend.key.size = unit(0.6, "lines"))
# Calcular la precisión y contar el número de observaciones por grupo
plot_positions <- positions %>%
dplyr::group_by(position, targetL) %>%
dplyr::summarize(acc = mean(correct_pos, na.rm = TRUE),
n = dplyr::n()) %>%
ggplot2::ggplot(ggplot2::aes(x = as.numeric(position), y = acc, group = targetL,
fill = targetL, color = targetL, lty = targetL)) +
ggplot2::geom_line(size = 0.70, alpha = 0.6) +
ggplot2::geom_point(ggplot2::aes(size = n), shape = 21, color = "black", alpha = 0.6) +
ggplot2::scale_linetype_manual(values = custom_linetypes) +
theme(panel.border = element_rect(colour = "black", fill = NA),
panel.background = element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.line = element_blank()) +
ylab("Proportion (%) of correct phonemes") +
xlab("Phoneme position") +
guides(fill = guide_legend(title = "Word Length"),
lty = guide_legend(title = "Word Length"),
color = guide_legend(title = "Word Length"),
size = guide_legend(title = "Datapoints")) +
theme_gray() +
theme(legend.position = "right",
legend.key.size = unit(0.6, "lines"))
df_to_classify = IGC_long_phon
df_to_classify = sunflower::IGC_long_phon_sample
m_w2v = word2vec::read.word2vec(file = "dependency-bundle/sbw_vectors.bin", normalize = TRUE)
errors_classified = df_to_classify %>%
check_lexicality(item_col = "item", response_col = "response", criterion = "database") %>%
get_formal_similarity(item_col = "item", response_col = "response",
attempt_col = "Attempt", group_cols = c("ID", "item_ID")) %>%
get_semantic_similarity(item_col = "item", response_col = "response", model = m_w2v) %>%
classify_errors(response_col = "response", item_col = "item",
access_col = "accessed", RA_col = "RA", also_classify_RAs = T)
errors_classified %>%
select(ID, item_ID, item, response, RA, Attempt, correct, nonword:comment) %>%
head(8) %>% knitr::kable()
errors_classified %>%
dplyr::select(ID, item_ID, item, response, RA, Attempt, correct, nonword:comment) %>%
head(8) %>% knitr::kable()
# Calcular la precisión y contar el número de observaciones por grupo
plot_positions <- positions %>%
group_by(position, targetL) %>%
summarize(acc = mean(correct_pos, na.rm = TRUE),
n = n()) %>%
ggplot(aes(x = as.numeric(position), y = acc, group = targetL,
fill = targetL, color = targetL, lty = targetL)) +
geom_line(size = 0.70, alpha = 0.6) +
geom_point(aes(size = n), shape = 21, color = "black", alpha = 0.6) +
scale_linetype_manual(values = custom_linetypes) +
theme(panel.border = element_rect(colour = "black", fill = NA),
panel.background = element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.line = element_blank()) +
ylab("Proportion (%) of correct phonemes") +
xlab("Phoneme position") +
guides(fill = guide_legend(title = "Word Length"),
lty = guide_legend(title = "Word Length"),
color = guide_legend(title = "Word Length"),
size = guide_legend(title = "Datapoints")) +
papaja::theme_apa() +
theme(legend.position = "right",
legend.key.size = unit(0.6, "lines"))
df_to_formal_metrics = readxl::read_xlsx("manuscript/data/1-Gutiérrez-Cordero_data_RAW.xlsx") %>%
dplyr::select(test, task_ID, task_type, ID, item_ID = task_item_ID, item, final_response, correct) %>%
dplyr::filter(test %in% c("SnodgrassVanderwart", "BETA", "EPLA", "Gutiérrez-Cordero")) %>%
dplyr::filter(!str_detect(task_type, "nonword")) %>%
dplyr::arrange(ID) %>%
dplyr::rename(clean_response = final_response) %>%
dplyr::mutate(ID = ID+1000)
df_to_formal_metrics = readxl::read_xlsx("manuscript/data/1-Gutiérrez-Cordero_data_RAW.xlsx")
df_to_formal_metrics
df_to_formal_metrics = readxl::read_xlsx("manuscript/data/1-Gutiérrez-Cordero_data_RAW.xlsx") %>%
dplyr::select(test, task_ID, task_type, ID, item_ID = task_item_ID, item, final_response, correct) %>%
dplyr::filter(test %in% c("SnodgrassVanderwart", "BETA", "EPLA", "Gutiérrez-Cordero")) %>%
dplyr::filter(!str_detect(task_type, "nonword")) %>%
dplyr::arrange(ID) %>%
dplyr::rename(clean_response = final_response) %>%
dplyr::mutate(ID = ID+1000)
df_to_formal_metrics = readxl::read_xlsx("manuscript/data/1-Gutiérrez-Cordero_data_RAW.xlsx") %>%
dplyr::select(test, task_ID, task_type, ID, item_ID = task_item_ID, item, final_response, correct) %>%
dplyr::filter(test %in% c("SnodgrassVanderwart", "BETA", "EPLA", "Gutiérrez-Cordero")) %>%
dplyr::filter(stringr::!str_detect(task_type, "nonword")) %>%
df_to_formal_metrics = readxl::read_xlsx("manuscript/data/1-Gutiérrez-Cordero_data_RAW.xlsx") %>%
dplyr::select(test, task_ID, task_type, ID, item_ID = task_item_ID, item, final_response, correct) %>%
dplyr::filter(test %in% c("SnodgrassVanderwart", "BETA", "EPLA", "Gutiérrez-Cordero")) %>%
dplyr::filter(!stringr::str_detect(task_type, "nonword")) %>%
dplyr::arrange(ID) %>%
dplyr::rename(clean_response = final_response) %>%
dplyr::mutate(ID = ID + 1000)
formal_metrics_computed = df_to_formal_metrics %>%
get_formal_similarity(item_col = "item_phon",
response_col = "response_phon",
attempt_col = "attempt",
group_cols = c("ID", "item_ID"))
df_to_formal_metrics = readxl::read_xlsx("manuscript/data/1-Gutiérrez-Cordero_data_RAW.xlsx") %>%
dplyr::select(test, task_ID, task_type, ID, item_ID = task_item_ID, item, final_response, correct) %>%
dplyr::filter(test %in% c("SnodgrassVanderwart", "BETA", "EPLA", "Gutiérrez-Cordero")) %>%
dplyr::filter(!stringr::str_detect(task_type, "nonword")) %>%
dplyr::arrange(ID) %>%
dplyr::rename(response = final_response) %>%
dplyr::mutate(ID = ID + 1000)
```{r}
formal_metrics_computed = df_to_formal_metrics %>%
get_formal_similarity(item_col = "item",
response_col = "response",
attempt_col = "attempt",
group_cols = c("ID", "item_ID"))
formal_metrics_computed
View(df_to_formal_metrics)
df_to_formal_metrics = readxl::read_xlsx("manuscript/data/1-Gutiérrez-Cordero_data_RAW.xlsx") %>%
dplyr::select(test, task_ID, task_type, ID, item_ID = task_item_ID, item, final_response) %>%
dplyr::filter(test %in% c("SnodgrassVanderwart", "BETA", "EPLA", "Gutiérrez-Cordero")) %>%
dplyr::filter(!stringr::str_detect(task_type, "nonword")) %>%
dplyr::arrange(ID) %>%
dplyr::rename(response = final_response) %>%
dplyr::mutate(ID = ID + 1000)
df_to_formal_metrics
df_to_formal_metrics = readxl::read_xlsx("manuscript/data/long_with_phon.xlsx") %>%
dplyr::select(test, task_ID, task_type, ID, item_ID = task_item_ID, item, final_response) %>%
dplyr::filter(test %in% c("SnodgrassVanderwart", "BETA", "EPLA", "Gutiérrez-Cordero")) %>%
dplyr::filter(!stringr::str_detect(task_type, "nonword")) %>%
dplyr::arrange(ID) %>%
dplyr::rename(response = final_response) %>%
dplyr::mutate(ID = ID + 1000)
df_to_formal_metrics = readxl::read_xlsx("manuscript/data/long_with_phon.xlsx") %>%
dplyr::select(test, task_ID, task_type, ID, item_ID = task_item_ID, item, final_response) %>%
dplyr::filter(test %in% c("SnodgrassVanderwart", "BETA", "EPLA", "Gutiérrez-Cordero")) %>%
dplyr::filter(!stringr::str_detect(task_type, "nonword")) %>%
dplyr::arrange(ID)
df_to_formal_metrics = readxl::read_xlsx("manuscript/data/long_with_phon.xlsx")
df_to_formal_metrics
df_to_formal_metrics = readxl::read_xlsx("manuscript/data/long_with_phon.xlsx") %>%
dplyr::select(test, task_ID, task_type, ID, item_ID = task_item_ID, item, final_response)
df_to_formal_metrics = readxl::read_xlsx("manuscript/data/long_with_phon.xlsx") %>%
dplyr::select(test, task_ID, task_type, ID, item_ID = task_item_ID, item, clean_response) %>%
dplyr::filter(test %in% c("SnodgrassVanderwart", "BETA", "EPLA", "Gutiérrez-Cordero")) %>%
dplyr::filter(!stringr::str_detect(task_type, "nonword")) %>%
dplyr::arrange(ID) %>%
dplyr::rename(response = final_response) %>%
dplyr::mutate(ID = ID + 1000)
df_to_formal_metrics = readxl::read_xlsx("manuscript/data/long_with_phon.xlsx") %>%
dplyr::select(test, task_ID, task_type, ID, item_ID = task_item_ID, item, clean_response)
df_to_formal_metrics
df_to_formal_metrics = readxl::read_xlsx("manuscript/data/long_with_phon.xlsx") %>%
dplyr::select(ID_general, test, task_modality, ID, item_ID = task_item_ID, item, response) %>%
dplyr::filter(test %in% c("SnodgrassVanderwart", "BETA", "EPLA", "Gutiérrez-Cordero")) %>%
dplyr::filter(!stringr::str_detect(task_type, "nonword")) %>%
dplyr::arrange(ID) %>%
dplyr::mutate(ID = ID + 1000)
df_to_formal_metrics = readxl::read_xlsx("manuscript/data/long_with_phon.xlsx") %>%
dplyr::select(ID_general, test, task_type, task_modality, ID, item_ID = task_item_ID, item, response) %>%
dplyr::filter(test %in% c("SnodgrassVanderwart", "BETA", "EPLA", "Gutiérrez-Cordero")) %>%
dplyr::filter(!stringr::str_detect(task_type, "nonword")) %>%
dplyr::arrange(ID) %>%
dplyr::mutate(ID = ID + 1000)
df_to_formal_metrics
df_to_formal_metrics = readxl::read_xlsx("manuscript/data/long_with_phon.xlsx") %>%
dplyr::select(ID_general, test, task_type, task_modality, ID, item_ID = task_item_ID, item, response) %>%
dplyr::filter(test %in% c("SnodgrassVanderwart", "BETA", "EPLA", "Gutiérrez-Cordero")) %>%
dplyr::filter(!stringr::str_detect(task_type, "nonword")) %>%
dplyr::arrange(ID)
formal_metrics_computed = df_to_formal_metrics %>%
get_formal_similarity(item_col = "item",
response_col = "response",
attempt_col = "attempt",
group_cols = c("ID", "item_ID"))
df_to_formal_metrics = readxl::read_xlsx("manuscript/data/long_with_phon.xlsx")
colnames(df_to_formal_metrics)
df_to_formal_metrics = readxl::read_xlsx("manuscript/data/long_with_phon.xlsx") %>%
dplyr::select(ID_general, test, task_type, task_modality, ID,
item_ID = task_item_ID, item, response,
item_phon = target_word_trasncrito_clean, response_phon = response_word_trasncrito_clean) %>%
dplyr::filter(test %in% c("SnodgrassVanderwart", "BETA", "EPLA", "Gutiérrez-Cordero")) %>%
dplyr::filter(!stringr::str_detect(task_type, "nonword")) %>%
dplyr::arrange(ID)
df_to_formal_metrics = readxl::read_xlsx("manuscript/data/long_with_phon.xlsx") %>%
dplyr::select(ID_general, test, task_type, task_modality, ID,
item_ID = task_item_ID, item, response,
item_phon = target_word_transcrito_clean, response_phon = response_word_transcrito_clean) %>%
dplyr::filter(test %in% c("SnodgrassVanderwart", "BETA", "EPLA", "Gutiérrez-Cordero")) %>%
dplyr::filter(!stringr::str_detect(task_type, "nonword")) %>%
dplyr::arrange(ID)
df_to_formal_metrics = readxl::read_xlsx("manuscript/data/long_with_phon.xlsx")
colnames(df_to_formal_metrics)
df_to_formal_metrics = readxl::read_xlsx("manuscript/data/long_with_phon.xlsx") %>%
dplyr::select(ID_general, test, task_type, task_modality, ID,
item_ID = task_item_ID, item, response, RA = cda_behavior,
item_phon = target_word_transcrito_clean, response_phon = response_word_transcrito_clean) %>%
dplyr::filter(test %in% c("SnodgrassVanderwart", "BETA", "EPLA", "Gutiérrez-Cordero")) %>%
dplyr::filter(!stringr::str_detect(task_type, "nonword")) %>%
dplyr::arrange(ID)
document()
install()
document()
install()
print(333333)
