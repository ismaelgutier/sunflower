response_col = "Response",
item_col = "item",
also_classify_RAs = T) %>%
dplyr::mutate(general_ID = dplyr::row_number())
IGC_step4 %>% dplyr::select(c(item, Response, general_ID, semantic, mixed, formal, unrelated, neologism, nonword)) %>% View()
IGC_step4_print_skinny <- IGC_step4 %>%
dplyr::filter(general_ID %in% c(2636, 790, 2570, 2492, 866, 300)) %>%
dplyr::select(general_ID, ID, task_item_ID, item, Response, RA, Attempt, lexicality, cosine_similarity, nonword:no_response) %>% rename(w2v_cos = cosine_similarity, item_ID = task_item_ID, attempt = Attempt, response = Response) %>% select(-c(general_ID, no_response))
IGC_step4_print_skinny <- IGC_step4 %>%
dplyr::filter(general_ID %in% c(2636, 790, 2570, 2492, 866, 300)) %>%
dplyr::select(general_ID, ID, task_item_ID, item, Response, RA,
Attempt, lexicality, cosine_similarity, nonword:no_response) %>%
rename(w2v_cos = cosine_similarity, item_ID = task_item_ID,
attempt = Attempt, response = Response) %>%
dplyr::select(-c(general_ID, no_response))
IGC_step4_print_skinny <- IGC_step4 %>%
dplyr::filter(general_ID %in% c(2636, 790, 2570, 2492, 866, 300)) %>%
dplyr::select(general_ID, ID, task_item_ID, item, Response, RA,
Attempt, lexicality, cosine_similarity, nonword:no_response) %>%
dplyr::rename(w2v_cos = cosine_similarity, item_ID = task_item_ID,
attempt = Attempt, response = Response) %>%
dplyr::select(-c(general_ID, no_response))
rmarkdown::paged_table(IGC_step4_print_skinny, options = list(rows.print = 9, align = "c"))
# Convertir el dataframe en un objeto tipo tabla usando tableGrob
table_plot4 <- gridExtra::tableGrob(
IGC_step4_print_skinny %>%
slice_head(n = 7)  # Seleccionar las primeras 7 filas
)
# Convertir el dataframe en un objeto tipo tabla usando tableGrob
table_plot4 <- gridExtra::tableGrob(
IGC_step4_print_skinny %>%
dplyr::slice_head(n = 7)  # Seleccionar las primeras 7 filas
)
# Crear un gráfico vacío para agregar la tabla, eliminando los márgenes
plot4 <- ggplot() +
theme_void() +  # Eliminar todos los elementos gráficos
annotation_custom(table_plot4)
# Mostrar el gráfico
plot4
ggsave("artworks_vignettes/f3.png", plot4, width = 13, height = 4.15, dpi = 600)
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
require(sunflower) # to work
#require(tidyverse) # to work along sunflower
#require(knitr) # to work in Rmarkdown
#require(kableExtra) # to work in Rmarkdown
#require(rmarkdown) # to work in Rmarkdown
require(ggplot2) #to plot
IGC = sunflower::IGC
#View(IGC)
IGC = IGC %>% dplyr::select(task_ID, task_type, ID, task_item_ID, item, final_response, correct) %>% dplyr::filter(task_ID == "SnodgrassVanderwart_nam")
rmarkdown::paged_table(IGC %>% dplyr::select(c(ID, task_item_ID, item, final_response)), options = list(rows.print = 8, align = "ccc"))
# Convertir el dataframe en un objeto tipo tabla usando tableGrob
table_plot <- gridExtra::tableGrob(IGC %>% dplyr::select(c(ID, task_item_ID, item, final_response)) %>%
dplyr::slice_head(n = 7))
# Crear un gráfico vacío para agregar la tabla, eliminando los márgenes
plot <- ggplot() +
theme_void() +  # Eliminar todos los elementos gráficos
annotation_custom(table_plot)
# Mostrar el gráfico
plot
ggsave("artworks_vignettes/f1_initial.png", plot, width = 8, height = 4.15, dpi = 600)
IGC_step1 = IGC %>% separate_responses(col_name = "final_response",
separate_with = ", ") %>%
get_attempts(first_production = Attempt_1, drop_blank_spaces = T)
IGC_step1_skinnydf = IGC_step1 %>% dplyr::select(-c(task_ID, task_type))
rmarkdown::paged_table(IGC_step1_skinnydf, options = list(rows.print = 25, align = "ccc"))
# Convertir el dataframe en un objeto tipo tabla usando tableGrob
table_plot2 <- gridExtra::tableGrob(IGC_step1_skinnydf %>% dplyr::select(c(ID, item_ID = task_item_ID, item, attempt = Attempt, response = Response)) %>%
dplyr::slice_head(n = 7))
# Crear un gráfico vacío para agregar la tabla, eliminando los márgenes
plot2 <- ggplot2::ggplot() +
ggplot2::theme_void() +  # Eliminar todos los elementos gráficos
ggplot2::annotation_custom(table_plot2)
# Mostrar el gráfico
plot2
ggsave("artworks_vignettes/f1_second.png", plot2, width = 8, height = 4.15, dpi = 600)
IGC_step2 = IGC_step1 %>% get_formal_similarity(item_col = "item",
response_col = "Response",
attempt_col = "Attempt",
group_cols = c("ID", "task_item_ID"))
IGC_step2_skinnydf = IGC_step2 %>% dplyr::select(-c(task_ID, task_type))
rmarkdown::paged_table(IGC_step2_skinnydf, options = list(rows.print = 25, align = "c"))
# Convertir el dataframe en un objeto tipo tabla usando tableGrob
table_plot3 <- gridExtra::tableGrob(
IGC_step2_skinnydf %>% dplyr::select(-c(responseL, targetL)) %>%
dplyr::mutate(across(where(is.numeric), ~ round(., 3))) %>%
dplyr::select(c(task_item_ID, item, Response, RA, Attempt, shared1char:DLd, JWd, pcc, CdA_diff = approach_diff)) %>%
dplyr::rename(item_ID = task_item_ID, diff_chars = diff_char_num, attempt = Attempt, response = Response) %>%
dplyr::slice_head(n = 7) # Seleccionar las primeras 7 filas
)
# Crear un gráfico vacío para agregar la tabla, eliminando los márgenes
plot3 <- ggplot() +
theme_void() +  # Eliminar todos los elementos gráficos
annotation_custom(table_plot3)
# Mostrar el gráfico
plot3
ggsave("artworks_vignettes/f2.png", plot3, width = 12, height = 4.15, dpi = 600)
# Convertir el dataframe en un objeto tipo tabla usando tableGrob
table_plot3b <- gridExtra::tableGrob(
IGC_step2_skinnydf %>%
dplyr::mutate(across(where(is.numeric), ~ round(., 3))) %>%
dplyr::select(c(item, Response, lcs, similarity_str,
match_str = itemL_adj_strict_match_pos)) %>%
dplyr::rename(response = Response) %>%
dplyr::slice_head(n = 7) # Seleccionar las primeras 7 filas
)
# Crear un gráfico vacío para agregar la tabla, eliminando los márgenes
plot3b <- ggplot() +
theme_void() +  # Eliminar todos los elementos gráficos
annotation_custom(table_plot3b)
# Mostrar el gráfico
plot3b
ggsave("artworks_vignettes/f2b.png", plot3b, width = 12, height = 4.15, dpi = 600)
IGC_step2.1 = IGC_step2 %>% positional_accuracy(match_col = "itemL_adj_strict_match_pos",
last_ID_col = "targetL")
IGC_step2.1_skinnydf = IGC_step2.1 %>% dplyr::select(-c(task_ID, correct, task_type)) %>%
dplyr::rename(item_ID = task_item_ID, attempt = Attempt, response = Response, position = Position)
rmarkdown::paged_table(IGC_step2.1_skinnydf, options = list(rows.print = 25, align = "c"))
# Convertir targetL a character para evitar problemas al combinar dataframes
positions_accuracy <- IGC_step2.1 %>%
dplyr::mutate(targetL = as.character(targetL))
# Duplicar y modificar el dataframe para crear 'positions_general'
positions_general <- positions_accuracy %>%
dplyr::mutate(targetL = "General")
# Combinar ambos dataframes
positions <- dplyr::bind_rows(positions_accuracy, positions_general)
# Especificar manualmente los niveles en el orden deseado
desired_levels <- c("3", "4", "5", "6", "7", "8", "9", "10", "11", "12",
"13", "14", "15", "17", "21", "22", "24", "48", "General")
# Convertir correct_pos a numérico y ordenar targetL como factor según desired_levels
positions <- positions %>%
dplyr::mutate(correct_pos = as.numeric(correct_pos),
targetL = factor(targetL, levels = desired_levels)) %>%
dplyr::arrange(correct_pos, targetL)
# Definir un conjunto de linetypes que se pueda repetir
custom_linetypes <- rep(c("solid", "dashed", "dotted", "longdash", "dotdash"),
length.out = nlevels(positions$targetL))
# Calcular la precisión y contar el número de observaciones por grupo
plot_positions <- positions %>%
dplyr::group_by(Position, targetL) %>%
dplyr::summarize(acc = mean(correct_pos, na.rm = TRUE)*100,
n = dplyr::n()) %>%
ggplot(aes(x = as.numeric(Position), y = acc, group = targetL,
fill = targetL, color = targetL, lty = targetL)) +
geom_line(size = 0.70, alpha = 0.6) +
geom_point(aes(size = n), shape = 21, color = "black", alpha = 0.6) +
scale_linetype_manual(values = custom_linetypes) +
theme(panel.border = element_rect(colour = "black", fill = NA),
panel.background = element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.line = element_blank()) +
ylab("Positional accuracy (%) ") +
xlab("Position") +
ylim(0, 100) +  # Aseguramos que el eje y muestre de 0 a 100
guides(fill = guide_legend(title = "Word Length"),
lty = guide_legend(title = "Word Length"),
color = guide_legend(title = "Word Length"),
size = guide_legend(title = "Datapoints"))  +
theme_grey(base_size = 12) +
theme(panel.grid = element_blank(),
axis.line = element_line(colour = "black"),
plot.title = element_text(hjust = 0.5),
legend.position = "right",
axis.title.x = element_text(margin = margin(t = 10)),
axis.title.y = element_text(margin = margin(r = 10)))
plot_positions
ggsave("artworks_vignettes/pa.png", plot = plot_positions, width = 10, height = 5)
m_w2v = word2vec::read.word2vec(file = file.choose(), normalize = F)
IGC_step2_clean = IGC %>%
separate_responses(
col_name = "final_response",
separate_with = ", ") %>%
get_attempts(
first_production = Attempt_1, drop_blank_spaces = T)  %>%
dplyr::select(task_ID, ID, task_item_ID, task_type, item, Response, RA, Attempt) %>%
get_formal_similarity(item_col = "item", response_col = "Response",
attempt_col = "Attempt",
group_cols = c("ID", "task_item_ID"))
IGC_step2clean_skinnydf = IGC_step2_clean %>% dplyr::select(-c(task_ID, task_type))
rmarkdown::paged_table(IGC_step2clean_skinnydf, options = list(rows.print = 25, align = "c"))
# remove some values leaving NAs to check that the functions work correctly
IGC_step2_cleanNA = IGC_step2_clean %>%
dplyr::mutate(
Response = dplyr::if_else(dplyr::row_number() == 2, NA_character_, Response),
item = dplyr::if_else(dplyr::row_number() == 3, NA_character_, item)
)
IGC_step3 <- IGC_step2_cleanNA %>%
check_lexicality(item_col = "item", response_col = "Response", criterion = "database") %>%
get_formal_similarity(item_col = "item", response_col = "Response",
attempt_col = "Attempt",
group_cols = c("ID", "task_item_ID")) %>%
get_semantic_similarity(item_col = "item", response_col = "Response", model = m_w2v)
# Compute accessed col
IGC_step3 = IGC_step3 %>%
dplyr::mutate(accessed = dplyr::if_else(Response == item, 1, 0))
IGC_step3_skinnydf = IGC_step3 %>% dplyr::select(-c(task_ID, task_type))
rmarkdown::paged_table(IGC_step3_skinnydf, options = list(rows.print = 25, align = "c"))
devtools::document()
devtools::document()
devtools::document()
print("ge")
install()
print("dd")
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
require(sunflower) # to work
require(tidyverse) # to work along sunflower
require(knitr) # to work in Rmarkdown
require(kableExtra) # to work in Rmarkdown
require(rmarkdown) # to work in Rmarkdown
IGC = sunflower::IGC
#colnames(IGC)
IGC = IGC %>% select(task_ID, task_type, ID, task_item_ID, item, final_response, correct)
paged_table(IGC, options = list(rows.print = 25, align = "ccc"))
IGC_step1 = IGC %>% separate_responses(col_name = "final_response",
separate_with = ", ") %>%
get_attempts(first_production = Attempt_1, drop_blank_spaces = T)
IGC_step1_skinnydf = IGC_step1 %>% dplyr::select(-c(task_ID, task_type))
paged_table(IGC_step1_skinnydf, options = list(rows.print = 25, align = "ccc"))
IGC_step2 = IGC_step1 %>% get_formal_similarity(item_col = "item",
response_col = "Response",
attempt_col = "Attempt",
group_cols = c("ID", "task_item_ID"))
IGC_step2_skinnydf = IGC_step2 %>% dplyr::select(-c(task_ID, task_type))
paged_table(IGC_step2_skinnydf, options = list(rows.print = 25, align = "c"))
IGC_step2.1 = IGC_step2 %>% positional_accuracy(match_col = "itemL_adj_strict_match_pos",
last_ID_col = "targetL")
IGC_step2.1_skinnydf = IGC_step2.1 %>% dplyr::select(-c(task_ID, correct, task_type))
paged_table(IGC_step2.1_skinnydf, options = list(rows.print = 25, align = "c"))
IGC = sunflower::IGC
m_w2v = word2vec::read.word2vec(file = file.choose(), normalize = TRUE)
IGC_step2_clean = IGC %>%
separate_responses(
col_name = "final_response",
separate_with = ", ") %>%
get_attempts(
first_production = Attempt_1, drop_blank_spaces = T)  %>%
select(task_ID, ID, task_item_ID, task_type, item, Response, RA, Attempt) %>%
get_formal_similarity(item_col = "item", response_col = "Response",
attempt_col = "Attempt",
group_cols = c("ID", "task_item_ID"))
IGC_step2clean_skinnydf = IGC_step2_clean %>% dplyr::select(-c(task_ID, task_type))
paged_table(IGC_step2clean_skinnydf, options = list(rows.print = 25, align = "c"))
# remove some values leaving NAs to check that the functions work correctly
IGC_step2_cleanNA = IGC_step2_clean %>%
mutate(
Response = if_else(row_number() == 2, NA_character_, Response),
item = if_else(row_number() == 3, NA_character_, item)
)
IGC_step3 <- IGC_step2_cleanNA %>%
check_lexicality(item_col = "item", response_col = "Response", criterion = "database") %>%
get_formal_similarity(item_col = "item", response_col = "Response",
attempt_col = "Attempt",
group_cols = c("ID", "task_item_ID")) %>%
get_semantic_similarity(item_col = "item", response_col = "Response", model = m_w2v)
# Compute accessed col
IGC_step3 = IGC_step3 %>%
mutate(accessed = if_else(Response == item, 1, 0))
IGC_step3_skinnydf = IGC_step3 %>% dplyr::select(-c(task_ID, task_type))
paged_table(IGC_step3_skinnydf, options = list(rows.print = 25, align = "c"))
# Convertir targetL a character para evitar problemas al combinar dataframes
positions_accuracy <- positions_accuracy %>%
dplyr::mutate(targetL = as.character(targetL))
git config --global user.name "Ismael Gutiérrez Cordero"
usethis::create_github_token()
credentials::set_github_pat("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")
credentials::set_github_pat("XeqCo3IHi7AdSeB2SwpgwDT3Wkiij64P1kSC")
git config --global user.name "Ismael Gutiérrez Cordero"
credentials::set_github_pat("XeqCo3IHi7AdSeB2SwpgwDT3Wkiij64P1kSC")
install()
install()
print(done)
m_w2v = word2vec::read.word2vec(file = "dependency-bundle/sbw_vectors.bin", normalize = TRUE)
df_to_formal_metrics = load("data/mine/IGC_mine.RData") %>%
dplyr::select(-c(modality, task_modality,task_type, test, task)) # keep some relevant columns
df_to_formal_metrics = load("data/mine/IGC_mine.rda") %>%
dplyr::select(-c(modality, task_modality,task_type, test, task)) # keep some relevant columns
df_to_formal_metrics = load("data/mine/IGC_mine.rda")
df_to_formal_metrics
df_to_formal_metrics = load("data/mine/IGC_mine.rdata") %>%
dplyr::select(-c(modality, task_modality,task_type, test, task)) # keep some relevant columns
df_to_formal_metrics = load("data/mine/IGC_mine.rdata")
df_to_formal_metrics
df_to_formal_metrics = load("data/mine/IGC_mine.rda") %>%
dplyr::select(-c(modality, task_modality,task_type, test, task)) # keep some relevant columns
View(IGC)
df_to_formal_metrics = load("data/mine/IGC_mine.rda") %>%
dplyr::select(-c(modality, task_modality,task_type, test, task)) # keep some relevant columns
df_to_formal_metrics = load("data/mine/IGC_mine.rda") %>%
as.data.frame() %>%
dplyr::select(-c(modality, task_modality,task_type, test, task)) # keep some relevant columns
df_to_formal_metrics = load("data/mine/IGC_mine.rda")
df_to_formal_metrics
df_to_formal_metrics = read_excel("data-raw/IGC.xlsx") %>%
dplyr::select(-c(modality, task_modality,task_type, test, task)) # keep some relevant columns
devtools::document()
devtools::document()
devtools::install()
print("hello")
positions_accuracy = formal_metrics_computed %>%
positional_accuracy(match_col = "adj_strict_match_pos")
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>",
fig.path = "man/figures/README-",
out.width = "100%"
)
require("sunflower")
require("tidyverse")
require("htmltools")
df_to_formal_metrics = sunflower::IGC_long_phon %>%
dplyr::select(-c(modality, task_modality,task_type, test, task)) # keep some relevant columns
formal_metrics_computed = df_to_formal_metrics %>%
get_formal_similarity(item_col = "item",
response_col = "response",
attempt_col = "Attempt",
group_cols = c("ID", "item_ID"))
require("sunflower")
require("tidyverse")
require("htmltools")
df_to_formal_metrics = sunflower::IGC_long_phon %>%
dplyr::select(-c(modality, task_modality,task_type, test, task)) # keep some relevant columns
formal_metrics_computed = df_to_formal_metrics %>%
get_formal_similarity(item_col = "item",
response_col = "response",
attempt_col = "Attempt",
group_cols = c("ID", "item_ID"))
require("sunflower")
require("tidyverse")
require("htmltools")
install()
document()
devtools::document()
prin("hello")
print("hello")
devtools::install()
print("hola")
install()
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>",
fig.path = "man/figures/README-",
out.width = "100%"
)
require("sunflower")
require("tidyverse")
require("htmltools")
df_to_formal_metrics = sunflower::IGC_long_phon %>%
dplyr::select(-c(modality, task_modality,task_type, test, task)) # keep some relevant columns
formal_metrics_computed = df_to_formal_metrics %>%
get_formal_similarity(item_col = "item",
response_col = "response",
attempt_col = "Attempt",
group_cols = c("ID", "item_ID"))
formal_metrics_computed %>% head(8) %>% knitr::kable()
positions_accuracy = formal_metrics_computed %>%
positional_accuracy(match_col = "adj_strict_match_pos")
formal_metrics_computed
positions_accuracy = formal_metrics_computed %>%
positional_accuracy(match_col = "itemL_adj_strict_match_pos")
formal_metrics_computed
positions_accuracy = formal_metrics_computed %>%
positional_accuracy(item_col = item, response_col = response, match_col = "itemL_adj_strict_match_pos")
positions_accuracy = formal_metrics_computed %>%
positional_accuracy(item_col = "item", response_col = "response", match_col = "itemL_adj_strict_match_pos")
positions_accuracy %>% head(8) %>% knitr::kable()
# Convertir targetL a character para evitar problemas al combinar dataframes
positions_accuracy <- positions_accuracy %>%
mutate(targetL = as.character(targetL))
# Duplicar y modificar el dataframe para crear 'positions_general'
positions_general <- positions_accuracy %>%
mutate(targetL = "General")
# Combinar ambos dataframes
positions <- bind_rows(positions_accuracy, positions_general)
# Especificar manualmente los niveles en el orden deseado
desired_levels <- c("3", "4", "5", "6", "7", "8", "9", "10", "11", "12",
"13", "14", "15", "17", "21", "22", "24", "48", "General")
# Convertir correct_pos a numérico y ordenar targetL como factor según desired_levels
positions <- positions %>%
mutate(correct_pos = as.numeric(correct_pos),
targetL = factor(targetL, levels = desired_levels)) %>%
arrange(correct_pos, targetL)
# Definir un conjunto de linetypes que se pueda repetir
custom_linetypes <- rep(c("solid", "dashed", "dotted", "longdash", "dotdash"),
length.out = nlevels(positions$targetL))
# Calcular la precisión y contar el número de observaciones por grupo
plot_positions <- positions %>%
group_by(Position, targetL) %>%
summarize(acc = mean(correct_pos, na.rm = TRUE),
n = n()) %>%
ggplot(aes(x = as.numeric(Position), y = acc, group = targetL,
fill = targetL, color = targetL, lty = targetL)) +
geom_line(size = 0.70, alpha = 0.6) +
geom_point(aes(size = n), shape = 21, color = "black", alpha = 0.6) +
scale_linetype_manual(values = custom_linetypes) +
theme(panel.border = element_rect(colour = "black", fill = NA),
panel.background = element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.line = element_blank()) +
ylab("Proportion (%) of correct phonemes") +
xlab("Phoneme position") +
guides(fill = guide_legend(title = "Word Length"),
lty = guide_legend(title = "Word Length"),
color = guide_legend(title = "Word Length"),
size = guide_legend(title = "Datapoints")) +
theme_gray() +
theme(legend.position = "right",
legend.key.size = unit(0.6, "lines"))
plot_positions
df_to_classify = sunflower::IGC_long %>% select(-c(modality, task_modality,task_type, test, task))
m_w2v = word2vec::read.word2vec(file = "dependency-bundle/sbw_vectors.bin", normalize = TRUE)
errors_classified = df_to_classify %>%
check_lexicality(item_col = "item", response_col = "Response", criterion = "database") %>%
get_formal_similarity(item_col = "item", response_col = "Response",
attempt_col = "Attempt", group_cols = c("ID", "item_ID")) %>%
get_semantic_similarity(item_col = "item", response_col = "Response", model = m_w2v) %>%
classify_errors(response_col = "Response", item_col = "item",
access_col = "accessed", RA_col = "RA", also_classify_RAs = T)
errors_classified = df_to_classify %>%
check_lexicality(item_col = "item", response_col = "Response", criterion = "database") %>%
get_formal_similarity(item_col = "item", response_col = "Response",
attempt_col = "Attempt", group_cols = c("ID", "item_ID")) %>%
get_semantic_similarity(item_col = "item", response_col = "Response", model = m_w2v) %>%
classify_errors(response_col = "Response", item_col = "item",
access_col = "accessed", RA_col = "RA", also_classify_RAs = T)
document()
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>",
fig.path = "man/figures/README-",
out.width = "100%"
)
require("sunflower")
require("tidyverse")
require("htmltools")
df_to_formal_metrics = sunflower::IGC_long_phon %>%
dplyr::select(-c(modality, task_modality,task_type, test, task)) # keep some relevant columns
formal_metrics_computed = df_to_formal_metrics %>%
get_formal_similarity(item_col = "item",
response_col = "response",
attempt_col = "Attempt",
group_cols = c("ID", "item_ID"))
formal_metrics_computed %>% head(8) %>% knitr::kable()
positions_accuracy = formal_metrics_computed %>%
positional_accuracy(item_col = "item", response_col = "response", match_col = "itemL_adj_strict_match_pos")
positions_accuracy %>% head(8) %>% knitr::kable()
# Convertir targetL a character para evitar problemas al combinar dataframes
positions_accuracy <- positions_accuracy %>%
mutate(targetL = as.character(targetL))
# Duplicar y modificar el dataframe para crear 'positions_general'
positions_general <- positions_accuracy %>%
mutate(targetL = "General")
# Combinar ambos dataframes
positions <- bind_rows(positions_accuracy, positions_general)
# Especificar manualmente los niveles en el orden deseado
desired_levels <- c("3", "4", "5", "6", "7", "8", "9", "10", "11", "12",
"13", "14", "15", "17", "21", "22", "24", "48", "General")
# Convertir correct_pos a numérico y ordenar targetL como factor según desired_levels
positions <- positions %>%
mutate(correct_pos = as.numeric(correct_pos),
targetL = factor(targetL, levels = desired_levels)) %>%
arrange(correct_pos, targetL)
# Definir un conjunto de linetypes que se pueda repetir
custom_linetypes <- rep(c("solid", "dashed", "dotted", "longdash", "dotdash"),
length.out = nlevels(positions$targetL))
# Calcular la precisión y contar el número de observaciones por grupo
plot_positions <- positions %>%
group_by(Position, targetL) %>%
summarize(acc = mean(correct_pos, na.rm = TRUE),
n = n()) %>%
ggplot(aes(x = as.numeric(Position), y = acc, group = targetL,
fill = targetL, color = targetL, lty = targetL)) +
geom_line(size = 0.70, alpha = 0.6) +
geom_point(aes(size = n), shape = 21, color = "black", alpha = 0.6) +
scale_linetype_manual(values = custom_linetypes) +
theme(panel.border = element_rect(colour = "black", fill = NA),
panel.background = element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.line = element_blank()) +
ylab("Proportion (%) of correct phonemes") +
xlab("Phoneme position") +
guides(fill = guide_legend(title = "Word Length"),
lty = guide_legend(title = "Word Length"),
color = guide_legend(title = "Word Length"),
size = guide_legend(title = "Datapoints")) +
theme_gray() +
theme(legend.position = "right",
legend.key.size = unit(0.6, "lines"))
plot_positions
df_to_classify = sunflower::IGC_long %>% select(-c(modality, task_modality,task_type, test, task))
m_w2v = word2vec::read.word2vec(file = "dependency-bundle/sbw_vectors.bin", normalize = TRUE)
errors_classified = df_to_classify %>%
check_lexicality(item_col = "item", response_col = "Response", criterion = "database") %>%
get_formal_similarity(item_col = "item", response_col = "Response",
attempt_col = "Attempt", group_cols = c("ID", "item_ID")) %>%
get_semantic_similarity(item_col = "item", response_col = "Response", model = m_w2v) %>%
classify_errors(response_col = "Response", item_col = "item",
access_col = "accessed", RA_col = "RA", also_classify_RAs = T)
document()
print()
print(2)
install()
print(3)
errors_classified = df_to_classify %>%
