---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# sunflower: A Package to Assess and Categorize Language Production Errors

<!-- badges: start -->

![](https://img.shields.io/badge/sunflower-v._0.2.0-orange?style=flat&logo=github&link=https%3A%2F%2Fgithub.com%2Fismaelgutier%2Fsunflower) [![License: GPL v3](https://img.shields.io/badge/License-GPLv3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0) ![](https://img.shields.io/badge/Language-grey?style=flat&logo=R&color=grey&link=https%3A%2F%2Fwww.r-project.org%2F)

<!-- badges: end -->

<div align="justify">

The goal of *sunflower* is to help to manage multiple response data, compute formal similarity indices to assess the quality of oral and written productions in patients with aphasia and other related disorders such as apraxia of speech in Spanish, and classify these productions according to classical typological in the field of Speech Therapy and Neuropsychology of Language. 

*sunflower* partially relies on natural language processing models, such as word2vec, to compute semantic similarity measures. The outputs provided by this package facilitate statistical analyses in [R](https://www.r-project.org/), a common tool in our field used for data wrangling, visualization and analysis.

## Installation

*sunflower* can be installed as an R package with:

```r
install.packages("devtools")
devtools::install_github("ismaelgutier/sunflower")
```
*sunflower* can use R native pipes (`|>`), it is recommended to install the [*tidyverse* package](https://www.tidyverse.org/). This will allow you to use the *tidyverse* pipes (`%>%`) and functions from packages like *dplyr*, *readr*, and *ggplot2* to support the work.

```r
install.packages("tidyverse")
```

## How to use

```{r include=FALSE}
require("sunflower")
require("tidyverse")
require("htmltools")
```

### Loading the packages

We only need to load two packages: *sunflower* and *tidyverse* for support.

```r
require("sunflower")
require("tidyverse")
```

### Compute Formal Quality Indexes

```{r}
df_to_formal_metrics = sunflower::IGC_long_phon %>% select(-c(modality, task_modality,task_type, test, task))


formal_metrics_computed = df_to_formal_metrics %>% 
                                  get_formal_indexes(item_col = "item_phon",
                                       response_col = "response_phon",
                                       attempt_col = "Attempt",
                                       group_cols = c("ID", "item_ID"))

formal_metrics_computed %>% head(8) %>% knitr::kable()

```
`Note`: Move the dataframe to the right to see all the columns and metrics.


### Obtain Positional Accuracy Data

```{r message=FALSE}
positions_accuracy = formal_metrics_computed %>% 
  position_scores(match_col = "itemL_adj_strict_match_pos", last_ID_col = "targetL")

positions_accuracy %>% head(8) %>% knitr::kable()
```
```{r include=FALSE}
# Convertir targetL a character para evitar problemas al combinar dataframes
positions_accuracy <- positions_accuracy %>%
  mutate(targetL = as.character(targetL))

# Duplicar y modificar el dataframe para crear 'positions_general'
positions_general <- positions_accuracy %>%
  mutate(targetL = "General")

# Combinar ambos dataframes
positions <- bind_rows(positions_accuracy, positions_general)

# Especificar manualmente los niveles en el orden deseado
desired_levels <- c("3", "4", "5", "6", "7", "8", "9", "10", "11", "12",
                    "13", "14", "15", "17", "21", "22", "24", "48", "General")

# Convertir correct_pos a numÃ©rico y ordenar targetL como factor segÃºn desired_levels
positions <- positions %>%
  mutate(correct_pos = as.numeric(correct_pos),
         targetL = factor(targetL, levels = desired_levels)) %>%
  arrange(correct_pos, targetL)

# Definir un conjunto de linetypes que se pueda repetir
custom_linetypes <- rep(c("solid", "dashed", "dotted", "longdash", "dotdash"),
                        length.out = nlevels(positions$targetL))

# Calcular la precisiÃ³n y contar el nÃºmero de observaciones por grupo
plot_positions <- positions %>%
  group_by(Position, targetL) %>%
  summarize(acc = mean(correct_pos, na.rm = TRUE),
            n = n()) %>%
  ggplot(aes(x = as.numeric(Position), y = acc, group = targetL,
             fill = targetL, color = targetL, lty = targetL)) +
  geom_line(size = 0.70, alpha = 0.6) +
  geom_point(aes(size = n), shape = 21, color = "black", alpha = 0.6) +
  scale_linetype_manual(values = custom_linetypes) +
  theme(panel.border = element_rect(colour = "black", fill = NA),
        panel.background = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.line = element_blank()) +
  ylab("Proportion (%) of correct phonemes") +
  xlab("Phoneme position") +
  guides(fill = guide_legend(title = "Word Length"),
         lty = guide_legend(title = "Word Length"),
         color = guide_legend(title = "Word Length"),
         size = guide_legend(title = "Datapoints")) + 
  theme_gray() +
  theme(legend.position = "right",
        legend.key.size = unit(0.6, "lines"))

```

***Note.*** A plot depicting the positions' accuracy of 14,418 datapoints.

```{r plot_positions, out.width = "75%", fig.align="center", echo=FALSE}
plot_positions
```

### Classify Errors

```{r include=FALSE}
df_to_classify = sunflower::IGC_long %>% select(-c(modality, task_modality,task_type, test, task))

wordlist <- read_csv(file = file.choose(), 
                     col_names = FALSE, 
                     show_col_types = FALSE, 
                     locale = locale(asciify = TRUE)) %>% as.vector()

m_w2v = word2vec::read.word2vec(file = file.choose(), normalize = TRUE)
```

```{r}
errors_classified = df_to_classify %>% 
  get_formal_similarity(target_col = "item", response_col = "Response", 
                            item_type = "task_type", source1 = wordlist) %>%
  get_semantic_similarity(target_col = "item", response_col = "Response", model = m_w2v) %>%
  classify_errors(access_col = "accessed", RA_col = "RA", response_col = "Response", classify_RAs = T)

errors_classified %>% head(8) %>% knitr::kable()
```

***Notes.*** Move the dataframe to the right to see all the columns and errors.

To enable *sunflower* to classify errors, it requires good "nutrients". These are (1) word list sources, such as `source1 = wordlist`, a .txt file located in the dependency-bundle zip, which can be found in our supplementary [OSF repository mirror](https://osf.io/akuxv/); users can set up to 3 sources. And (2) a NLP model, in our case this is `model = m_w2v`, a binary file containing a Spanish Billion Word embeddings corpus created using the word2vec algorithm, also located in the same zip file (see the markdown in the vignettes for further information). 

The quality of the classification performed directly depends on the quality of the source files. Some words might not be available in the `wordlist`, which comes from a prestigious Spanish dictionary (RAE). We cannot solve this issue except by using double-checking and human supervision.


----

Any suggestions, comments, or questions about the functionality of the package are warmly welcomed. If you are interested in contributing to the project, please feel free to contact us.

Thank you ðŸŒ»

